from nltk import word_tokenize
from nltk import pos_tag
import re

ANSWER_SEPERATOR = "Answer"

def tokenization(sentences):
	words = word_tokenize(sentences)
	return words

def omit_stop_word(list_of_string):
    from nltk.corpus import stopwords
    stop_words = set(stopwords.words('english'))
    return [s for s in list_of_string if s not in stop_words]

def is_numerical(tag):
    return tag == 'CD'


# Simple way to tagging the single word 
def part_of_speech_tagging(list_of_string):
    return [t for t in pos_tag(list_of_string)]


def parse_noun(sentences):
    print "### START FUNCTION parse_noun()###"
    print "sentences= {}".format(sentences)
    words = tokenization(sentences)
    # # Get rig NLTK limitations:
    # # Remove unneccessary characters: '.', '*' at the end of each tokenized words returned by NLTK
    # words = get_expected_tokenized_words(words)
    # # print 'expected_words = {}'.format(words)

    list_pos = part_of_speech_tagging(words)

    # Get list of all nouns and pronouns from lis_pos
    import string
    punctuations = list(string.punctuation)
    # Get all nouns and pronouns from lis_pos
    allNoun = [word for word, tag in list_pos if tag in ['NN', 'NNP'] and word not in punctuations ]
    allNoun = set(allNoun)     
    allNoun = list(allNoun)

    import nltk
    from nltk.corpus import wordnet

    # Create a list of dictionary data for each string variables (noun or pronoun)
    # list_dict = []
    list_dict = {} # use dict instead of list

    for i in range(len(allNoun)):
        synonyms = []
        for syn in wordnet.synsets(allNoun[i]):
            for l in syn.lemmas:
                synonyms.append(l.name)

        # Old format of string variable
        # list_dict.append (
        #     {
        #         "name" : "string{}".format(i),
        #         "default" : allNoun[i],
        #         "value" : allNoun[i],
        #         "synonyms" : list(set([allNoun[i]] + synonyms) )
        #     }
        # )

        # New format of string variable
        var_index = "string{}".format(i)
        context_default = "context0"

        # list_dict.append(
        #     {
        #         var_index:
        #         {
        #             "name": var_index,
        #             "original_text": allNoun[i],
        #             "default": allNoun[i],
        #             "value": allNoun[i],
        #             "context": context_default,
        #             "context_list": {
        #                 context_default: {
        #                     "name": "Synonyms of " + allNoun[i],
        #                     "help": "Pure list of words (NN and NNP) generated by NLTK from the original text '" + allNoun[i] + "'",
        #                     "synonyms": list(set([allNoun[i]] + synonyms)),
        #                     "select": "true"
        #                 }
        #             }
        #         }
        #     }
        # )

        list_dict[var_index] = {
                    "name": var_index,
                    "original_text": allNoun[i],
                    "default": allNoun[i],
                    "value": allNoun[i],
                    "context": context_default,
                    "context_list": {
                        context_default: {
                            "name": "Synonyms of " + allNoun[i],
                            "help": "Pure list of words (NN and NNP) generated by NLTK from the original text '" + allNoun[i] + "'",
                            "synonyms": list(set([allNoun[i]] + synonyms)),
                            "select": "true"
                        }
                    }
                }

        #print list_dict[i]

    print "string_variables= {}".format(list_dict)
    print "### END FUNCTION parse_noun()###"

    return list_dict


def create_string_variables(list_pos):
    print "### START FUNCTION create_string_variables()###"
    # print "list_pos= {}".format(list_pos)

    # Get list of all nouns and pronouns from lis_pos
    import string
    punctuations = list(string.punctuation)
    # Get all nouns and pronouns from lis_pos
    allNoun = [word for word, tag in list_pos if tag in ['NN', 'NNP'] and word not in punctuations ]
    allNoun = set(allNoun)
    allNoun = list(allNoun)

    import nltk
    from nltk.corpus import wordnet

    # Create a dictionary data for each string variables (noun or pronoun)
    string_vars_dict = {} # use dict instead of list

    for i in range(len(allNoun)):
        synonyms = []
        for syn in wordnet.synsets(allNoun[i]):
            for l in syn.lemmas:
                synonyms.append(l.name)

        # New format of string variable
        var_index = "string{}".format(i)
        context_default = "context0"

        string_vars_dict[var_index] = {
                    "name": var_index,
                    "original_text": allNoun[i],
                    "default": allNoun[i],
                    "value": allNoun[i],
                    "context": context_default,
                    "context_list": {
                        context_default: {
                            "name": "Synonyms of text '" + allNoun[i] + "' (Default)",
                            "help": "List of words (NN and NNP) generated by NLTK from the original text '" + allNoun[i] + "'",
                            "synonyms": list(set([allNoun[i]] + synonyms)),
                            "select": "true"
                        }
                    }
                }

        #print string_vars_dict[i]

    # print "string_variables= {}".format(string_vars_dict)
    print "### END FUNCTION create_string_variables()###"

    return string_vars_dict


def parse_answer(answer, variables):
    words = tokenization(answer)
    answer_template = ""
    for variable in variables:
        for i in range(len(words)):
            if words[i] == variable[0]:
                words[i] = '[{}]'.format(variable[1]['var'])
    answer_template = ' '.join(words)
    return answer_template

def parse_answer_v2(answer, variables):
    print "### START FUNCTION parse_answer_v2()###"
    words = tokenization(answer)
    print "tokenized words= {}".format(words)
    print "variables= {}".format(variables)

    answer_template = ""
    for i in range(len(variables)):
        for j in range(len(words)):
            print "i = {}, numeric_var = {}, tokenized_word = {}, matched = {}".format(str(i),variables[i][0], words[j], words[j] == variables[i][0])
            if words[j] == variables[i][0]:
                words[j] = '[{}]'.format(variables[i][1]['var{}'.format(i)]['name'])
    answer_template = ' '.join(words)

    print "answer_template= {}".format(answer_template)
    print "### END FUNCTION parse_answer_v2()###"

    return answer_template


def parse_answer_improved(answer, variables):
    print "### START FUNCTION parse_answer_improved()###"
    # words = tokenization(answer)
    # print "tokenized words= {}".format(words)
    # print "variables= {}".format(variables)

    # New method:
    # Replace original text by variable help to improve performance
    answer_template = answer
    for var_name, num_variable in variables.iteritems():
        # Only replace original numeric text which has at least one space before and after (i.e. a separated number).
        # TODO: Canh to update re pattern to correct bug about missing variables' values here
        answer_template = re.sub(r" {}".format(num_variable["original_text"]), " [{}]".format(num_variable["name"]),
                                   answer_template)

    # print "answer_template= {}".format(answer_template)
    print "### END FUNCTION parse_answer_improved()###"

    return answer_template

def parse_question_v2(question_text):
    print "### START FUNCTION parse_question_v2()###"
    words = tokenization(question_text)
    print "tokenized words= {}".format(words)

    # Get rig NLTK limitations:
    # Remove unneccessary characters: '.', '*' at the end of each tokenized words returned by NLTK
    words = get_expected_tokenized_words(words)
    print 'expected_words = {}'.format(words)

    list_pos = part_of_speech_tagging(words)
    print "list_pos= {}".format(list_pos)

    # Get numeric variables from list_pos
    variables = []
    for word in list_pos:
        try:
            if is_numerical(word[1]) and isinstance(int(word[0]),int):
                variables.append((word[0],'int'))
        except ValueError:
            print "oops !! There is a string or float in this word '" + str(word) + "' at character '" + str(word[0]) + "' or '" + str(word[1]) + "'"
            try:
                if isinstance(float(word[0]), float):
                    variables.append( (word[0],'float') )
            except ValueError:
                print "oops: the last call this is the word '" + str(word) + "'"
        print "at word = {}, numeric variables= {}".format(word, variables)

    variables = list(set(variables))
    print "variables = {}".format(variables)

    numeric_variables = []
    for i in range(len(variables)):
        print 'i = {}, variables[i] = {}'.format(str(i), variables[i])
        numeric_variables.append( (variables[i][0],
            {
                'var{}'.format(i) :
                {
                    'name' : 'var{}'.format(i) ,
                    'min_value' : 1,
                    'max_value' : 100,
                    'type' : variables[i][1],
                    'decimal_places' : 2
                }
            })
        )
    print "i = {}, numeric_variables_structured_list= {}".format(str(i), numeric_variables)

    # Create string variables
    # string_variables = parse_noun(question_text)
    string_variables = create_string_variables(list_pos)

    # Build question template
    question_template = ""

    # Put numeric variables into the template
    for i in range(len(numeric_variables)):
        for j in range(len(words)):
            if words[j] == numeric_variables[i][0]: # check if text is a number ?
                words[j] = '[{}]'.format(numeric_variables[i][1]['var{}'.format(i)]['name'] )
    question_template = ' '.join(words)

    # Put string variables into the template
    for var_name, variable in string_variables.iteritems():
         # Only replace original text which has at least one space before it.
         question_template = re.sub(" {}".format(variable["original_text"]), " [{}] ".format(variable["name"]), question_template )

    print "question template= {}".format(question_template)
    print "numeric_variables= {}".format(numeric_variables)
    print "string_variables= {}".format(string_variables)
    print "### END FUNCTION parse_question_v2()###"

    return question_template, numeric_variables, string_variables

def parse_question_improved(question_text):
    print "### START FUNCTION parse_question_improved()###"
    words = tokenization(question_text)
    print "tokenized words= {}".format(words)

    # Eliminate NLTK limitations:
    # Remove unneccessary characters: '.', '*' at the end of each tokenized words returned by NLTK
    expected_words = get_expected_tokenized_words(words)
    print 'expected_words = {}'.format(expected_words)
    # Identify type of each tokenized words
    list_pos = part_of_speech_tagging(expected_words)
    print "list_pos= {}".format(list_pos)

    # Get numeric variables from list_pos
    variables = []
    for word in list_pos:
        try:
            if is_numerical(word[1]) and isinstance(int(word[0]),int):
                variables.append((word[0],'int'))
        except ValueError:
            print "oops !! There is a string or float in this word '" + str(word) + "' at character '" + str(word[0]) + "' or '" + str(word[1]) + "'"
            try:
                if isinstance(float(word[0]), float):
                    variables.append( (word[0],'float') )
            except ValueError:
                print "oops: the last call this is the word '" + str(word) + "'"
        # print "at word = {}, variables= {}".format(word, variables)

    variables = list(set(variables))
    # print "variables = {}".format(variables)

    # New method: use dictionary indexed by var name
    # Replace original text by variable help to improve performance
    numeric_variables = {}
    for i in range(len(variables)):
        var_index = 'var{}'.format(i)
        # print 'i = {}, variables[i] = {}'.format(str(i), variables[i])
        numeric_variables[var_index] = {
                                            'name': var_index,
                                            'original_text': variables[i][0],
                                            'min_value': 1,
                                            'max_value': 100,
                                            'type': variables[i][1],
                                            'decimal_places': 2
        }
    # print "numeric_variables = {}".format(numeric_variables)

    # Create string variables
    # string_variables = parse_noun(question_text)
    string_variables = create_string_variables(list_pos)

    # Generate question template
    # New method
    # Replace original text by variable help to improve performance
    question_template = question_text
    # Put numeric variables' name into the question template
    for var_name, num_variable in numeric_variables.iteritems():
        # Only replace original text which has at least one space before it.
        question_template = re.sub(" {}".format(num_variable["original_text"]), " [{}]".format(num_variable["name"]),
                                   question_template)

    # Put string variables' name into the question template
    for var_name, string_variable in string_variables.iteritems():
         # Only replace original text which has at least one space before it.
         question_template = re.sub(" {}".format(string_variable["original_text"]), " [{}]".format(string_variable["name"]), question_template )

    print "question template= {}".format(question_template)
    print "numeric_variables= {}".format(numeric_variables)
    print "string_variables= {}".format(string_variables)
    print "### END FUNCTION parse_question_improved()###"

    return question_template, numeric_variables, string_variables

def get_expected_tokenized_words(words):
    '''
    Remove unneccessary characters: '.', '*' at the end of each tokenized words returned by NLTK

    :param words: List of tokenized words
    :return: expected_words: Removed unneccessary characters: '.', '*' at the end of each tokenized words
    '''
    expected_words = []
    for word in words:
        # Remove characters: '.' or '*' at the end word
        word = re.sub('(\.|\*)$', '', word)
        expected_words.append(word)

    return expected_words


def parse_question(sentences):

    words = tokenization(sentences)
    list_pos = part_of_speech_tagging(words)
    variables = []
    for word in list_pos:
        try:
            if is_numerical(word[1]) and isinstance(int(word[0]),int):
                variables.append((word[0],'int'))
        except ValueError:
            print "oops !! There is a string or float in the list"
            try:
                if isinstance(float(word[0]), float):
                    variables.append((word[0],'float'))
            except ValueError:
                print "oops: the last call this is the string"
    variables = list(set(variables))
    variable_names =  []
    for i in range(len(variables)):
        variable_names.append((variables[i][0],
            {
                'var'   : 'var{}'.format(i),
                'type'   : variables[i][1],
                'shadow' :
                {
                    'var{}'.format(i) : 
                    {   'name' : 'var{}'.format(i) ,
                        'min_value' : 1,
                        'max_value' : 100,
                        'type' : variables[i][1],
                        'decimal_places' : 2
                    }
                },
            })
        )
    string_variables = parse_noun(sentences)
    template = ""
    for variable in variable_names:
        for i in range(len(words)):
            if words[i] == variable[0]:
                words[i] = '[{}]'.format(variable[1]['var'])
    template = ' '.join(words)
    for variable in string_variables:
        template = re.sub( " {} ".format(variable["default"]) , " [{}] ".format(variable["name"]), template )
    return template, variable_names, string_variables

    
if __name__ == '__main__':
    # ex1 = """
	# You throw a ball straight up in the air with an initial speed of 40 m/s. [g = 9.8 m/s2]. Write a
    #     code to determine the maximum height (H) the ball rise from the release point?
    # """
    # ans1 = """
    #         x = 40
    #         g = 9.8
    #         H = 2*x/g
    #         """

    ex1 = """Given 7 apples and 5 rings. One apple cost 200.8 USD, one ring cost 3,5 USD.
Calculate the total price of them?"""

    ans1 = """x = 7 * 200.8 + 5 * 3,5"""

    print 'original question = ' + ex1
    print 'original anser = ' + ans1
    question_template, numeric_variables, string_variables = parse_question_improved(ex1)
    #noun = parse_noun(ex1)
    answer_template = parse_answer_improved(ans1, numeric_variables)
    print "question_template = {}".format(question_template)
    print "numeric_variables = {}".format(numeric_variables)
    print "string_variables = {}".format(string_variables)
    # print "answer_template = " + answer_template
			
		

		

